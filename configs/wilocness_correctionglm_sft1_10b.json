{
    "name": "correctionglm",
    "language_model": true,
    "pretrained_model": "os.path.join(MODEL_ROOT_DIR, 'glm-10b')",
    "torch_dtype": "torch.bfloat16",
    "use_lora": true,
    "lora_rank": 32,
    "bf16": true,
    "ds_config": null,
    "load_in_8bit": false,
    "model_type": "all",
    "num_labels": 3,
    "output_dropout_prob": 0.2,
    "loss_ignore_id": -100,
    "loss_detach": false,
    "loss_reduce": "mean",
    "cache_dir": ".cache",
    "load_cache": true,
    "streaming": false,
    "num_proc_trainset": null,
    "max_train_source_length": 128,
    "max_eval_source_length": 256,
    "prompt": "",
    "detection_load_way": "detections",
    "detection_results": {
        "train": "results_add/correctionglm-wilocness-train_eval_infer-20240328-0900/train/detection_results.json",
        "valid": "results_add/correctionglm-wilocness-train_eval_infer-20240328-0900/valid/detection_results.json",
        "test": null
    },
    "gradient_accumulation_steps": 16,
    "train_batch_size": 8,
    "eval_batch_size": 4,
    "detection_batch_size": 8,
    "detection_loss_weight": 10,
    "alpha": [
        1,
        2,
        2
    ],
    "epoch": 5,
    "warmup_steps": 100,
    "max_steps": 2000000,
    "lr": 5e-05,
    "lr_scheduler": "polynomial",
    "weight_decay": 0.0001,
    "logging_steps": 10,
    "eval_step": 100,
    "save_step": 100,
    "save_strategy": "epoch",
    "early_stop": 10,
    "eval_key": "eval_ad_accuracy",
    "pre_split_length_for_infer": null,
    "max_infer_source_length": 384,
    "detection_only": false,
    "post_process": [
        "en_test_py3"
    ],
    "load_config_keys": [
        "model_type",
        "prompt",
        "num_labels"
    ],
    "keep_threshold": null,
    "error_threshold": null,
    "insert_threshold": null,
    "num_beams": 3,
    "max_new_tokens": 10
}